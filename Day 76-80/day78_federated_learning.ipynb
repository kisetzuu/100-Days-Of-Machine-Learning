{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install syft==0.7.0 torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from syft.frameworks.torch.fl import VirtualWorker\n",
    "from syft import TorchHook\n",
    "\n",
    "# Hook PyTorch to enable Federated Learning\n",
    "hook = TorchHook(torch)\n",
    "\n",
    "# Simulate two clients\n",
    "client1 = VirtualWorker(hook, id=\"client1\")\n",
    "client2 = VirtualWorker(hook, id=\"client2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform and load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Split dataset between clients\n",
    "mnist_train = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "mnist_train_client1, mnist_train_client2 = torch.utils.data.random_split(mnist_train, [30000, 30000])\n",
    "\n",
    "# Send datasets to the clients\n",
    "train_loader_client1 = torch.utils.data.DataLoader(mnist_train_client1, batch_size=64, shuffle=True)\n",
    "train_loader_client2 = torch.utils.data.DataLoader(mnist_train_client2, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_on_client(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Train locally on client1 and client2\n",
    "optimizer_client1 = optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer_client2 = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1, 3):  # Two epochs for demonstration\n",
    "    loss_client1 = train_on_client(model, train_loader_client1, optimizer_client1)\n",
    "    loss_client2 = train_on_client(model, train_loader_client2, optimizer_client2)\n",
    "    print(f\"Epoch {epoch}, Loss on Client 1: {loss_client1:.4f}, Loss on Client 2: {loss_client2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_aggregation(global_model, client_models):\n",
    "    # Average weights of client models\n",
    "    global_state_dict = global_model.state_dict()\n",
    "    for key in global_state_dict:\n",
    "        global_state_dict[key] = torch.stack([client.state_dict()[key] for client in client_models]).mean(dim=0)\n",
    "    global_model.load_state_dict(global_state_dict)\n",
    "\n",
    "# Create copies of the model for clients\n",
    "client_model1 = Net()\n",
    "client_model2 = Net()\n",
    "\n",
    "client_model1.load_state_dict(model.state_dict())\n",
    "client_model2.load_state_dict(model.state_dict())\n",
    "\n",
    "# Perform aggregation\n",
    "federated_aggregation(model, [client_model1, client_model2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST('./data', train=False, transform=transform), batch_size=64, shuffle=False)\n",
    "\n",
    "# Evaluate the global model\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    return correct / len(test_loader.dataset)\n",
    "\n",
    "accuracy = evaluate(model, test_loader)\n",
    "print(f\"Global Model Test Accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
