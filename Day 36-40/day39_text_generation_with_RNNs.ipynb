{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a text dataset and preprocess it by cleaning and tokenizing the text.\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Sample text dataset (you can replace this with your own dataset)\n",
    "text = \"\"\"\n",
    "Once upon a time in a land far, far away, there lived a kind and brave king.\n",
    "The king loved his people and worked hard to ensure their happiness and prosperity.\n",
    "\"\"\"\n",
    "\n",
    "# Clean and tokenize the text\n",
    "text = text.lower().replace(\",\", \"\").replace(\".\", \"\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "\n",
    "# Convert text to sequences\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "input_sequences = []\n",
    "for line in text.split(\"\\n\"):\n",
    "    token_list = tokenizer.texts_to_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an LSTM-based model for text generation.\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "def build_text_generation_model(total_words, input_length):\n",
    "    model = Sequential([\n",
    "        Embedding(total_words, 100, input_length=input_length),  # Embedding layer\n",
    "        LSTM(150, return_sequences=True),                       # LSTM layer\n",
    "        LSTM(100),                                              # Another LSTM layer\n",
    "        Dense(total_words, activation=\"softmax\")                # Output layer with vocabulary size\n",
    "    ])\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = build_text_generation_model(total_words, max_sequence_len - 1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the prepared text data.\n",
    "\n",
    "history = model.fit(X, y, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to generate new text sequences based on a given seed text.\n",
    "\n",
    "def generate_text(seed_text, next_words, max_sequence_len, tokenizer, model):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding=\"pre\")\n",
    "        predicted = np.argmax(model.predict(token_list), axis=-1)[0]\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "\n",
    "# Generate text with a seed sentence\n",
    "seed_text = \"the king loved\"\n",
    "generated_text = generate_text(seed_text, next_words=20, max_sequence_len=max_sequence_len, tokenizer=tokenizer, model=model)\n",
    "print(\"Generated Text:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to generate new text sequences based on a given seed text.\n",
    "\n",
    "def generate_text(seed_text, next_words, max_sequence_len, tokenizer, model):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding=\"pre\")\n",
    "        predicted = np.argmax(model.predict(token_list), axis=-1)[0]\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "\n",
    "# Generate text with a seed sentence\n",
    "seed_text = \"the king loved\"\n",
    "generated_text = generate_text(seed_text, next_words=20, max_sequence_len=max_sequence_len, tokenizer=tokenizer, model=model)\n",
    "print(\"Generated Text:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss and accuracy to evaluate model performance.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(history.history[\"loss\"], label=\"Loss\")\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot accuracy\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Accuracy\")\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
