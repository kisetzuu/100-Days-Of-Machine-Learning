{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Use NLTK to create an extractive summarizer by selecting key sentences from the text based on word frequency.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sent_tokenize, word_tokenize\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "# Use NLTK to create an extractive summarizer by selecting key sentences from the text based on word frequency.\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "import heapq\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Sample text data\n",
    "text = \"\"\"Machine learning is a field of artificial intelligence (AI) that enables computers to learn from data without being explicitly programmed. \n",
    "It has applications in various fields such as healthcare, finance, marketing, and agriculture. Machine learning algorithms are classified into supervised, \n",
    "unsupervised, and reinforcement learning.\"\"\"\n",
    "\n",
    "# Preprocess text and remove stopwords\n",
    "sentences = sent_tokenize(text)\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "words = word_tokenize(re.sub(r'[^\\w\\s]', '', text.lower()))\n",
    "\n",
    "# Compute word frequencies\n",
    "word_frequencies = FreqDist(word for word in words if word not in stop_words)\n",
    "\n",
    "# Calculate sentence scores based on word frequencies\n",
    "sentence_scores = {}\n",
    "for sentence in sentences:\n",
    "    for word in word_tokenize(sentence.lower()):\n",
    "        if word in word_frequencies:\n",
    "            if sentence not in sentence_scores:\n",
    "                sentence_scores[sentence] = word_frequencies[word]\n",
    "            else:\n",
    "                sentence_scores[sentence] += word_frequencies[word]\n",
    "\n",
    "# Extract top sentences for summary\n",
    "summary_sentences = heapq.nlargest(2, sentence_scores, key=sentence_scores.get)\n",
    "summary = ' '.join(summary_sentences)\n",
    "print(\"Extractive Summary:\\n\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Hugging Face Transformers to create an abstractive summarizer, generating new sentences that summarize the text.\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained summarization model\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "# Example text for summarization\n",
    "text = \"\"\"Machine learning is a field of artificial intelligence (AI) that enables computers to learn from data without being explicitly programmed. \n",
    "It has applications in various fields such as healthcare, finance, marketing, and agriculture. Machine learning algorithms are classified into supervised, \n",
    "unsupervised, and reinforcement learning.\"\"\"\n",
    "\n",
    "# Generate abstractive summary\n",
    "abstractive_summary = summarizer(text, max_length=50, min_length=25, do_sample=False)[0]['summary_text']\n",
    "print(\"Abstractive Summary:\\n\", abstractive_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare extractive and abstractive summarization results to understand their different approaches and outputs.\n",
    "\n",
    "print(\"Extractive Summary:\\n\", summary)\n",
    "print(\"\\nAbstractive Summary:\\n\", abstractive_summary)\n",
    "\n",
    "# Extractive summarization selects key sentences directly from the original text.\n",
    "# Abstractive summarization generates new sentences to capture the main ideas concisely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ROUGE Score to evaluate the quality of summaries by comparing them with a reference summary.\n",
    "\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Define reference summary and candidate summaries\n",
    "reference_summary = \"\"\"Machine learning is a field of AI enabling computers to learn from data with diverse applications.\"\"\"\n",
    "extractive_summary = summary\n",
    "abstractive_summary = abstractive_summary\n",
    "\n",
    "# Initialize ROUGE scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "extractive_rouge = scorer.score(reference_summary, extractive_summary)\n",
    "abstractive_rouge = scorer.score(reference_summary, abstractive_summary)\n",
    "\n",
    "print(\"Extractive Summary ROUGE Score:\\n\", extractive_rouge)\n",
    "print(\"\\nAbstractive Summary ROUGE Score:\\n\", abstractive_rouge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the length of summaries by modifying parameters, such as the number of sentences in extractive summarization or length constraints in abstractive summarization.\n",
    "\n",
    "# Extractive summarization: change the number of sentences\n",
    "num_sentences = 3\n",
    "summary_sentences = heapq.nlargest(num_sentences, sentence_scores, key=sentence_scores.get)\n",
    "adjusted_summary = ' '.join(summary_sentences)\n",
    "print(\"Adjusted Extractive Summary:\\n\", adjusted_summary)\n",
    "\n",
    "# Abstractive summarization: adjust min and max length\n",
    "adjusted_abstractive_summary = summarizer(text, max_length=60, min_length=30, do_sample=False)[0]['summary_text']\n",
    "print(\"Adjusted Abstractive Summary:\\n\", adjusted_abstractive_summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
