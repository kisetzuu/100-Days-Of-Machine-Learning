{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/dD2405/Twitter_Sentiment_Analysis/master/train.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display dataset sample\n",
    "print(\"Dataset Sample:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text.lower())\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['encoded_label'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "# Tokenize text\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(df['cleaned_text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['cleaned_text'])\n",
    "\n",
    "# Pad sequences\n",
    "max_len = 100\n",
    "X = pad_sequences(sequences, maxlen=max_len)\n",
    "y = to_categorical(df['encoded_label'])\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nTraining Data Shape: {X_train.shape}\")\n",
    "print(f\"Test Data Shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=128, input_length=max_len),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "# Display training complete message\n",
    "print(\"\\nModel Training Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict category\n",
    "def predict_category(text, model, tokenizer, label_encoder, max_len):\n",
    "    cleaned_text = clean_text(text)\n",
    "    sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])\n",
    "    return predicted_label[0]\n",
    "\n",
    "# Test the model with custom text\n",
    "sample_text = \"The government has announced new economic reforms.\"\n",
    "predicted_category = predict_category(sample_text, model, tokenizer, label_encoder, max_len)\n",
    "print(f\"\\nSample Text: {sample_text}\")\n",
    "print(f\"Predicted Category: {predicted_category}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
