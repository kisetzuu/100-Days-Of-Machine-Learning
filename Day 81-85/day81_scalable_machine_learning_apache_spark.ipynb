{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Scalable Machine Learning with Spark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"SparkSession Initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data_url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv\"\n",
    "columns = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"]\n",
    "data = spark.read.csv(data_url, schema=\",\".join(columns), header=False, inferSchema=True)\n",
    "\n",
    "# Display dataset schema and first few rows\n",
    "data.printSchema()\n",
    "data.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename target column and vectorize features\n",
    "data = data.withColumnRenamed(\"MEDV\", \"label\")\n",
    "feature_columns = data.columns[:-1]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "vectorized_data = assembler.transform(data).select(\"features\", \"label\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = vectorized_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Training Data Count: {train_data.count()}\")\n",
    "print(f\"Testing Data Count: {test_data.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Linear Regression model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Display model coefficients and intercept\n",
    "print(\"Coefficients:\", lr_model.coefficients)\n",
    "print(\"Intercept:\", lr_model.intercept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Evaluate model performance\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_path = \"spark_lr_model\"\n",
    "lr_model.write().overwrite().save(model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# Load the model\n",
    "loaded_model = LinearRegression.load(model_path)\n",
    "print(\"Model reloaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance\n",
    "for feature, coef in zip(feature_columns, lr_model.coefficients):\n",
    "    print(f\"Feature: {feature}, Coefficient: {coef:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
