{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the modelâ€™s accuracy on the test dataset.\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        # Make predictions\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the YOLOv5 repository and install dependencies.\n",
    "!git clone https://github.com/ultralytics/yolov5.git\n",
    "%cd yolov5\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained YOLOv5 model for inference on images or videos.\n",
    "\n",
    "from yolov5 import YOLO\n",
    "\n",
    "# Initialize the pre-trained YOLOv5 model\n",
    "model = YOLO('yolov5s')  # Use the smallest YOLOv5 model for speed\n",
    "\n",
    "# Display available YOLO models\n",
    "print(\"Available YOLOv5 models: yolov5s, yolov5m, yolov5l, yolov5x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform object detection on an image and visualize the results.\n",
    "\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load an image\n",
    "image_path = 'data/images/bus.jpg'  # Replace with your image path\n",
    "results = model(image_path)\n",
    "\n",
    "# Display results\n",
    "results.show()\n",
    "results.print()  # Print detection results (classes, confidence, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train YOLOv5 on a custom dataset by configuring a dataset YAML file.\n",
    "\n",
    "# Example command to train YOLOv5 (run in terminal or notebook shell)\n",
    "!python train.py --img 640 --batch 16 --epochs 50 --data data/coco128.yaml --weights yolov5s.pt\n",
    "\n",
    "# Replace 'data/coco128.yaml' with your custom dataset YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the YOLOv5 model on a test dataset.\n",
    "\n",
    "# Example command to evaluate\n",
    "!python val.py --weights yolov5s.pt --data data/coco128.yaml --img 640\n",
    "\n",
    "# Replace 'data/coco128.yaml' with your custom dataset YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the trained YOLOv5 model to ONNX or TensorRT for deployment.\n",
    "\n",
    "# Example command to export to ONNX\n",
    "!python export.py --weights yolov5s.pt --img 640 --batch 1 --device 0 --include onnx\n",
    "\n",
    "print(\"Model exported to ONNX format.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
