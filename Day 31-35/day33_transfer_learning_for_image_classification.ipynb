{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a small dataset (e.g., CIFAR-10) and preprocess it for transfer learning.\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to range [0, 1]\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Resize images to fit the pre-trained model's input size\n",
    "X_train = tf.image.resize(X_train, (224, 224))\n",
    "X_test = tf.image.resize(X_test, (224, 224))\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Test data shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained model like VGG16 or MobileNet without the top layers to adapt it for a new task.\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Load the pre-trained VGG16 model without the top layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model's layers\n",
    "base_model.trainable = False\n",
    "\n",
    "print(\"Base model layers frozen:\", not base_model.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom layers to the pre-trained base model for classifying CIFAR-10 images.\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "# Build the transfer learning model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')  # Output layer for 10 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the new dataset while keeping the pre-trained layers frozen.\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze some layers of the base model to fine-tune it for the specific dataset.\n",
    "\n",
    "# Unfreeze the last few layers of the base model\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-4]:  # Keep the first few layers frozen\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile the model with a lower learning rate for fine-tuning\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model\n",
    "history_fine = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the fine-tuned model on the test set and predict new samples.\n",
    "\n",
    "# Evaluate test accuracy\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy after Fine-Tuning:\", test_accuracy)\n",
    "\n",
    "# Predict a single image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_image = np.expand_dims(X_test[0], axis=0)  # Add batch dimension\n",
    "prediction = model.predict(sample_image)\n",
    "predicted_class = np.argmax(prediction)\n",
    "\n",
    "# Plot the sample image with predicted class\n",
    "plt.imshow(X_test[0])\n",
    "plt.title(f\"Predicted Class: {predicted_class}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
