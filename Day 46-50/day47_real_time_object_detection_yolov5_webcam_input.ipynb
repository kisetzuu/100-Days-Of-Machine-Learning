{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the YOLOv5 repository\n",
    "!git clone https://github.com/ultralytics/yolov5.git\n",
    "%cd yolov5\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import cv2\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Load the pre-trained YOLOv5 model\n",
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")  # YOLOv5 small model\n",
    "print(\"YOLOv5 model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the webcam for real-time object detection.\n",
    "\n",
    "def real_time_detection(model):\n",
    "    cap = cv2.VideoCapture(0)  # 0 for the default webcam\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Perform object detection on the current frame\n",
    "        results = model(frame)\n",
    "\n",
    "        # Render the results on the frame\n",
    "        frame_with_detections = results.render()[0]\n",
    "\n",
    "        # Display the output\n",
    "        cv2.imshow(\"Real-Time Object Detection\", frame_with_detections)\n",
    "\n",
    "        # Break on 'q' key press\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the real-time detection\n",
    "real_time_detection(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a single frame for understanding the outputs.\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "if ret:\n",
    "    # Perform detection on a single frame\n",
    "    results = model(frame)\n",
    "    \n",
    "    # Extract bounding boxes, confidence, and labels\n",
    "    detections = results.pandas().xyxy[0]  # Results as a pandas DataFrame\n",
    "    print(\"Detection Results:\")\n",
    "    print(detections)\n",
    "\n",
    "    # Display the frame with detections\n",
    "    frame_with_detections = results.render()[0]\n",
    "    cv2.imshow(\"Test Detection\", frame_with_detections)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detected frames to a local directory.\n",
    "\n",
    "import os\n",
    "\n",
    "# Directory to save detected frames\n",
    "output_dir = \"detected_frames\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def save_detected_frames(model):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Perform detection\n",
    "        results = model(frame)\n",
    "        frame_with_detections = results.render()[0]\n",
    "\n",
    "        # Save frame to output directory\n",
    "        output_path = os.path.join(output_dir, f\"frame_{frame_count}.jpg\")\n",
    "        cv2.imwrite(output_path, frame_with_detections)\n",
    "        frame_count += 1\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Saving Frames\", frame_with_detections)\n",
    "\n",
    "        # Break on 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Frames saved to '{output_dir}'.\")\n",
    "\n",
    "# Save frames\n",
    "save_detected_frames(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform object detection on a pre-recorded video file.\n",
    "\n",
    "video_path = \"path_to_your_video.mp4\"  # Replace with your video file path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Perform detection\n",
    "    results = model(frame)\n",
    "    frame_with_detections = results.render()[0]\n",
    "\n",
    "    # Display the output\n",
    "    cv2.imshow(\"Video Object Detection\", frame_with_detections)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
