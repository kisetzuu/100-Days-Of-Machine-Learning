{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset and visualize its distribution to understand how clustering works.\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data with 3 clusters\n",
    "X, y = make_blobs(n_samples=300, centers=3, cluster_std=1.0, random_state=42)\n",
    "\n",
    "# Plot the data points\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], s=50, alpha=0.7)\n",
    "plt.title(\"Data for Clustering\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use K-Means to group data points into clusters based on centroids.\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Initialize and fit K-Means model\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "y_kmeans = kmeans.fit_predict(X)\n",
    "\n",
    "# Plot K-Means clustering results\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, cmap='viridis', s=50, alpha=0.7)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, c='red', marker='X', label='Centroids')\n",
    "plt.title(\"K-Means Clustering\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Elbow Method to determine the optimal number of clusters for K-Means.\n",
    "\n",
    "inertia = []\n",
    "K_range = range(1, 10)\n",
    "\n",
    "# Calculate inertia for each K value\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the Elbow curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(K_range, inertia, marker='o')\n",
    "plt.title(\"Elbow Method for Optimal K\")\n",
    "plt.xlabel(\"Number of Clusters (K)\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DBSCAN to group data points based on density, capturing non-linear cluster shapes and identifying noise.\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Initialize and fit DBSCAN model\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "y_dbscan = dbscan.fit_predict(X)\n",
    "\n",
    "# Plot DBSCAN clustering results\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_dbscan, cmap='plasma', s=50, alpha=0.7)\n",
    "plt.title(\"DBSCAN Clustering\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the performance of K-Means and DBSCAN for different clustering scenarios.\n",
    "\n",
    "print(\"K-Means Summary:\")\n",
    "print(f\"Number of Clusters: {len(set(y_kmeans)) - (1 if -1 in y_kmeans else 0)}\")\n",
    "print(\"\\nDBSCAN Summary:\")\n",
    "print(f\"Number of Clusters (including noise): {len(set(y_dbscan)) - (1 if -1 in y_dbscan else 0)}\")\n",
    "print(f\"Noise Points: {sum(y_dbscan == -1)}\")\n",
    "\n",
    "# K-Means performs well for spherical clusters but struggles with non-linear shapes.\n",
    "# DBSCAN excels at non-linear clusters and detects outliers but requires tuning (eps and min_samples)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
