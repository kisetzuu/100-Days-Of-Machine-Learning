{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Gradient Boosting Regressor to predict continuous values by minimizing the error iteratively.\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Generate synthetic regression data\n",
    "X, y = make_regression(n_samples=1000, n_features=5, noise=0.1, random_state=42)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train Gradient Boosting Regressor\n",
    "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Training R^2 Score:\", gbr.score(X_train, y_train))\n",
    "print(\"Testing R^2 Score:\", gbr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Grid Search to optimize the hyperparameters of the Gradient Boosting Regressor.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [2, 3, 5]\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=3, scoring='r2', verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and performance\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best R^2 Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the importance of features in predicting the target variable using Gradient Boosting.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get feature importance scores\n",
    "feature_importances = gbr.feature_importances_\n",
    "features = [f\"Feature {i+1}\" for i in range(len(feature_importances))]\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(features, feature_importances, color='skyblue')\n",
    "plt.title(\"Feature Importance in Gradient Boosting Regressor\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Importance Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use XGBoost for regression and compare its performance with Gradient Boosting Regressor.\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize and train XGBoost Regressor\n",
    "xgboost = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "xgboost.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate XGBoost performance\n",
    "print(\"XGBoost Training R^2 Score:\", xgboost.score(X_train, y_train))\n",
    "print(\"XGBoost Testing R^2 Score:\", xgboost.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize residuals to assess the modelâ€™s prediction errors and identify patterns.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = gbr.predict(X_test)\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, residuals, color='blue', alpha=0.6)\n",
    "plt.axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "plt.title(\"Residuals of Gradient Boosting Regressor\")\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
