{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample dataset (e.g., the Iris dataset) and visualize its features.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "data['target'] = iris.target\n",
    "\n",
    "# Visualize the dataset\n",
    "sns.pairplot(data, hue='target', palette='bright', diag_kind=\"kde\")\n",
    "plt.suptitle(\"Pairplot of Iris Dataset\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to reduce the dataset's dimensionality while retaining maximum variance.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(iris.data)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)  # Reduce to 2 dimensions for visualization\n",
    "pca_data = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Convert PCA result to a DataFrame\n",
    "pca_df = pd.DataFrame(data=pca_data, columns=['Principal Component 1', 'Principal Component 2'])\n",
    "pca_df['target'] = iris.target\n",
    "\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data in the reduced 2D space to observe separability between classes.\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    data=pca_df,\n",
    "    x='Principal Component 1',\n",
    "    y='Principal Component 2',\n",
    "    hue='target',\n",
    "    palette='bright'\n",
    ")\n",
    "plt.title(\"PCA-Reduced Data\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.legend(title=\"Target\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the explained variance ratio to determine the number of components needed for PCA.\n",
    "\n",
    "# Compute explained variance for all components\n",
    "pca_full = PCA()\n",
    "pca_full.fit(scaled_data)\n",
    "explained_variance_ratio = pca_full.explained_variance_ratio_\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio.cumsum(), marker='o')\n",
    "plt.title(\"Cumulative Explained Variance by PCA Components\")\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the original data from the principal components and compare the reconstruction loss.\n",
    "\n",
    "# Project data into a reduced space and back\n",
    "pca_reduced = PCA(n_components=2)\n",
    "reduced_data = pca_reduced.fit_transform(scaled_data)\n",
    "reconstructed_data = pca_reduced.inverse_transform(reduced_data)\n",
    "\n",
    "# Calculate reconstruction loss (MSE)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "reconstruction_loss = mean_squared_error(scaled_data, reconstructed_data)\n",
    "print(\"Reconstruction Loss (MSE):\", reconstruction_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PCA as a preprocessing step for classification tasks.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca_data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a classifier on PCA-reduced data\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on PCA-Reduced Data:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
