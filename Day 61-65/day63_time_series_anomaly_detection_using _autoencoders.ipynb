{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, RepeatVector, TimeDistributed\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic time-series data\n",
    "np.random.seed(42)\n",
    "time = np.arange(0, 100, 0.1)\n",
    "sin_wave = np.sin(time)  # Generate sine wave\n",
    "noise = np.random.normal(0, 0.1, len(time))  # Add random noise\n",
    "data = sin_wave + noise\n",
    "\n",
    "# Introduce anomalies\n",
    "data[450:470] += 2  # Add spike anomalies\n",
    "data[700:720] -= 2  # Add dip anomalies\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time, data, label=\"Time Series Data\")\n",
    "plt.axvspan(45, 47, color=\"red\", alpha=0.3, label=\"Anomalies\")\n",
    "plt.axvspan(70, 72, color=\"red\", alpha=0.3)\n",
    "plt.title(\"Synthetic Time Series with Anomalies\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(data.reshape(-1, 1))\n",
    "\n",
    "# Create sequences for the Autoencoder\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "    return np.array(sequences)\n",
    "\n",
    "sequence_length = 50\n",
    "X = create_sequences(data_normalized, sequence_length)\n",
    "\n",
    "print(\"\\nInput Shape for Autoencoder:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM Autoencoder\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=(sequence_length, 1), return_sequences=True),\n",
    "    LSTM(32, activation='relu', return_sequences=False),\n",
    "    RepeatVector(sequence_length),\n",
    "    LSTM(32, activation='relu', return_sequences=True),\n",
    "    LSTM(64, activation='relu', return_sequences=True),\n",
    "    TimeDistributed(Dense(1))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "train_size = int(0.7 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, X_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "X_test_pred = model.predict(X_test)\n",
    "reconstruction_error = np.mean(np.abs(X_test_pred - X_test), axis=(1, 2))\n",
    "\n",
    "# Set a threshold for anomalies\n",
    "threshold = np.percentile(reconstruction_error, 95)\n",
    "print(\"\\nReconstruction Error Threshold:\", threshold)\n",
    "\n",
    "# Identify anomalies\n",
    "anomalies = reconstruction_error > threshold\n",
    "print(\"Number of Anomalies Detected:\", np.sum(anomalies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an anomaly plot\n",
    "anomaly_indices = np.where(anomalies)[0] + train_size + sequence_length\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time, data, label=\"Time Series Data\")\n",
    "plt.scatter(time[anomaly_indices], data[anomaly_indices], color=\"red\", label=\"Detected Anomalies\")\n",
    "plt.title(\"Anomaly Detection in Time Series Data\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of reconstruction errors\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(reconstruction_error, bins=50, alpha=0.75, label=\"Reconstruction Error\")\n",
    "plt.axvline(threshold, color='red', linestyle='dashed', linewidth=2, label='Threshold')\n",
    "plt.title(\"Reconstruction Error Distribution\")\n",
    "plt.xlabel(\"Reconstruction Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
